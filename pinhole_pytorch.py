# -*- coding: utf-8 -*-
"""Pinhole-pytorch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1btM5y7UZmZ4JuV22gOZjq3t6J1H18IJb

# Pinhole camera project overview

---


What we're going to do in this project?


*   Read collected images into python
*   Create preprocessing function for our data
*   Build neural network model
*   Feed data into the model and start training
*   Compare traning results and the groudtruth
"""

#make sure colab will have access to your google drive
from google.colab import drive
drive.mount('/content/drive')

"""# Step 1: Data loading"""

# import python libraries
import cv2
import os
import numpy as np
from PIL import Image

# check current working directory, make sure the data is stored in the directory
os.getcwd()

# if not, change working directory using the code below, replace your directory
os.chdir('/content/drive/MyDrive/Pinhole Project 2023')

os.getcwd()

# define the image loading function and resize all images to the same size
def load_images_from_folder(folder, target_size = (256, 256)):
    images = []
    for filename in os.listdir(folder):
        if filename == "blurring":
            continue
        if filename == "sharp":
            continue
        img = cv2.imread(os.path.join(folder,filename), 3)
        b,g,r = cv2.split(img)           # get b, g, r, cv2 uses bgr so we need to swith it to rgb
        img = cv2.merge([r,g,b])     # switch it to r, g, b
        img = np.array(img)
        #interpolation
        h, w = img.shape[:2]
        c = img.shape[2] if len(img.shape) > 2 else 1
        if h == w:
            return cv2.resize(img, target_size, cv2.INTER_AREA)

        dif = h if h > w else w

        interpolation = cv2.INTER_AREA if dif > (target_size[0]+target_size[1])//2 else cv2.INTER_CUBIC

        x_pos = (dif - w)//2
        y_pos = (dif - h)//2

        if len(img.shape) == 2:
            mask = np.zeros((dif, dif), dtype=img.dtype)
            mask[y_pos:y_pos+h, x_pos:x_pos+w] = img[:h, :w]
        else:
            mask = np.zeros((dif, dif, c), dtype=img.dtype)
            mask[y_pos:y_pos+h, x_pos:x_pos+w, :] = img[:h, :w, :]

        img1 = Image.open(os.path.join(folder,filename))
        new1 = cv2.resize(mask, target_size, interpolation)
        new1 = np.array(new1)
        images.append(new1)
    return images

#load the two groups of images
# there are 227 images from last year
blurry1 = load_images_from_folder("blurring", target_size=(256, 256))
gt1 = load_images_from_folder("sharp", target_size=(256, 256)) #gt means ground truth, which will be sharp images

print(len(blurry1))
print(len(gt1))

#load the remining images
blurry2 = load_images_from_folder("Blurry2", target_size=(256, 256))
gt2 = load_images_from_folder("Sharp2", target_size=(256, 256))

print(len(blurry2))
print(len(gt2))

#combine images
blurry = blurry1 + blurry2
gt = gt1 + gt2

#our total number of images
print(len(blurry))
print(len(gt))

#check if images are in the desired size
blurry[0].shape   #the first image, in the resized shape, the third dimension corresponds to RGB channels

gt[0].shape

#plot the resized image
import matplotlib.pyplot as plt
plt.imshow(gt2[0])

#####################################################
###############Rotate iamges#########################
#####################################################

from scipy.ndimage import rotate

def rotate_images(images, angle):
    """
    Rotates a list of images by a given angle in degrees.
    :param images: A list of images stored as numpy arrays.
    :param angle: The angle in degrees to rotate each image by.
    :return: A list of rotated images.
    """
    rotated_images = []
    for image in images:
        rotated_image = rotate(image, angle, reshape=False)
        rotated_images.append(rotated_image)
    return rotated_images

#rotate blurry images
rotated_blurry_90 = rotate_images(blurry, 90)
rotated_blurry_180 = rotate_images(blurry, 180)
rotated_blurry_270 = rotate_images(blurry, 270)

plt.imshow(rotated_blurry_90[0])

#rotate sharp images
rotated_gt_90 = rotate_images(gt, 90)
rotated_gt_180 = rotate_images(gt, 180)
rotated_gt_270 = rotate_images(gt, 270)

plt.imshow(rotated_gt_90[0])

#combine rotated images with original images to create the final dataset
blurry_all = blurry + rotated_blurry_90 + rotated_blurry_180 + rotated_blurry_270
gt_all = gt + rotated_gt_90 + rotated_gt_180 + rotated_gt_270

print(len(blurry_all)) # 387 * 4 = 1548
print(len(gt_all))

####################################################
###############ATTENTION############################
####################################################
#Please mare sure you change the data name to be 'blurry_all' and 'gt_all' in later implementations
#If you are still using the data name 'blurry' and 'gt', it only contains 307 unrotated images.

"""# Step 2: Data pre-processing
* Enhance the sharp images and make them brighter
* Split the dataset into training and testing sets
- (The function train_test_split can do it automatically for us, the argument test_size means the proportion of testing set,
which is generally set as 0.2, and the random_state is the seed to ramdomly select testing images. We set the random_state because we want to reproduce the same data split everytime we run the code.)
"""

# Sharp image enhancement method 1: using HSV image format and increasing V
def increase_brightness(img, value=50):
    #convert RGB image to HSV image
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv) #split H, S and V
    #adjust V
    lim = 255 - value
    v[v > lim] = 255
    v[v <= lim] += value
    #merge hsv
    final_hsv = cv2.merge((h, s, v))
    #convert HSV back to RGB
    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)
    return img

enhanced_gt_1 = [increase_brightness(img=gt_all[i]) for i in range(len(gt))] #applying brightness function to all images

#check on the first image
plt.imshow(enhanced_gt_1[3])

# Sharp image enhacement method 2: using the build-in function
from PIL import Image, ImageEnhance
enhanced_gt_2 = []
for i in range(len(gt_all)):
  # Convert the numpy array to a Pillow Image object
  img = Image.fromarray(gt_all[i])
  # Create an image enhancer object
  enhancer = ImageEnhance.Brightness(img)

  # Increase the brightness by a factor of 2, feel free to change the factor
  brightened_img = enhancer.enhance(2) #1.5 to 2.5
  enhanced_img = enhancer.enhance(2)
  enhanced_img = np.array(enhanced_img)
  enhanced_gt_2.append(enhanced_img)

plt.imshow(enhanced_gt_2[3])

#change the data type to float, because torch can only take float input later on
type(enhanced_gt_2[0])

# def standardize(img):
#   #standardize to [0, 1]
#   img = np.array(img)
#   img = img.astype('float64')
#   min_val = np.min(img)
#   max_val = np.max(img)
#   standardized_image = (img - min_val) / (max_val - min_val)
#   return standardized_image

# blurry = [standardize(blurry[i]) for i in range(len(blurry))]
# gt = [standardize(enhanced_gt_2[i]) for i in range(len(enhanced_gt_2))]

from sklearn.model_selection import train_test_split

blur_train, blur_test, gt_train, gt_test = train_test_split(blurry_all, enhanced_gt_2, test_size=0.2, random_state=21)
print(f'There are {len(blurry_all)} blurry images and {len(gt_all)} clear images.')  #these two number should be the same
print(f'The training set contains {len(blur_train)} images, and the testing set contains {len(blur_test)} images.') # the sum should add up to len(blurry)

plt.imshow(gt_train[0])

"""# Step 3: Build convolutional neural network from the torch library"""

import torch
import torch.nn as nn
import torch.nn.functional as F

# the input shape of neural network should be the same as the image size
in_shape = blurry[0].shape
print(in_shape)

class ConvAutoencoder(nn.Module):
    def __init__(self):
        super(ConvAutoencoder, self).__init__()

        # Encoder layers
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')

        # Decoder layers
        self.conv4 = nn.Conv2d(128, 64, kernel_size=3, padding=1)
        self.conv5 = nn.Conv2d(192, 32, kernel_size=3, padding=1)
        self.conv6 = nn.Conv2d(96, 3, kernel_size=3, padding=1)

    def forward(self, x):
        # Encoder
        x = F.relu(self.conv1(x))    #(32, 256, 256)
        reserve_x1 = x
        x = self.pool(x) #(32, 128, 128)
        x = F.relu(self.conv2(x)) #(64, 128, 128)
        reserve_x2 = x
        x = self.pool(x)  #(64, 64, 64)
        x = F.relu(self.conv3(x))  #(128, 64, 64)
        reserve_x3 = x
        x = self.pool(x) #(128, 32, 32)

        # Decoder

        x = F.relu(self.conv4(x)) #(64, 32, 32)
        x = self.upsample(x) #(64, 64, 64)
        x = torch.cat([x, reserve_x3], dim=1) #(64+128=192, 64, 64)
        x = F.relu(self.conv5(x)) #(32, 64, 64)
        x = self.upsample(x) #(32, 128, 128)
        x = torch.cat([x, reserve_x2], dim=1) #(32+64=96, 128, 128)
        x = F.relu(self.conv6(x))  #(3, 128, 128)
        x = self.upsample(x) #(3, 256, 256)


        return x

"""# Step 4: Training model

* Convert the data into tensorflow-compatible format
* The data is originally a list of images with size (256, 256, 3), but we want a numpy array of shape (length, 256, 256, 3)
* In order to do this, we stack images along the first dimension
"""

# convert training data
gt_train_ = np.stack(gt_train)
blur_train_ = np.stack(blur_train)
print(gt_train_.shape, blur_train_.shape)

# torch require the input in shape (N, C, H, W)
gt_train_ = np.transpose(gt_train_, (0, 3, 1, 2))
blur_train_ = np.transpose(blur_train_, (0, 3, 1, 2))
print(gt_train_.shape, blur_train_.shape)

# convert testing data
gt_test_ = np.stack(gt_test)
blur_test_ = np.stack(blur_test)
print(gt_test_.shape, blur_test_.shape)

# torch require the input in shape (N, C, H, W)
gt_test_ = np.transpose(gt_test_, (0, 3, 1, 2))
blur_test_ = np.transpose(blur_test_, (0, 3, 1, 2))
print(gt_test_.shape, blur_test_.shape)

# convert data from array to tensor
gt_train_ = torch.from_numpy(gt_train_)
blur_train_ = torch.from_numpy(blur_train_)
gt_test_ = torch.from_numpy(gt_test_)
blur_test_ = torch.from_numpy(blur_test_)

# from torchvision import transforms
# normalizer = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
# gt_train_ = normalizer(gt_train_)
# blur_train_ = normalizer(blur_train_)
# gt_test_ = normalizer(gt_test_)
# blur_test_ = normalizer(blur_test_)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Instantiate the ConvAutoencoder model
model = ConvAutoencoder()
# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)
# model.eval()
model = model.to(device)

# Define loss function
MSELoss = nn.MSELoss()
L1Loss = nn.L1Loss()

# Define optimizer
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# send data to GPU
gt_train_ = gt_train_.to(device)
blur_train_ = blur_train_.to(device)
gt_test_ = gt_test_.to(device)
blur_test_ = blur_test_.to(device)

from torchsummary import summary
summary(model, input_size=(3, 256, 256))

# Define the training function
def run_an_epoch(epoch, model, blurry_imgs_train, sharp_imgs_train, blurry_imgs_test, sharp_imgs_test):
    #train
    model.train()
    # inputs_train = blurry_imgs_train.to(device)
    optimizer.zero_grad()

    outputs_train = model(blurry_imgs_train)
    loss_train = MSELoss(outputs_train, sharp_imgs_train) + L1Loss(outputs_train, sharp_imgs_train)
    loss_train.backward()
    optimizer.step()
    epoch_loss_train = loss_train / len(blurry_imgs_train)

    #validation
    model.eval()
    with torch.no_grad():
      # inputs_test = blurry_imgs_test.to(device)
      outputs_test = model(blurry_imgs_test)
      loss_test = MSELoss(outputs_test, sharp_imgs_test) + L1Loss(outputs_test, sharp_imgs_test)

    epoch_loss_test = loss_test / len(blurry_imgs_test)
    print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss_train:.4f}, Test Loss: {epoch_loss_test:.4f}")
    print(f"----------------------------------")

    return epoch_loss_train, epoch_loss_test

def run_an_epoch(epoch, model, blurry_imgs_train, sharp_imgs_train, blurry_imgs_test, sharp_imgs_test, batch_size=32):
    #train
    model.train()

    train_loss = 0.0
    num_batches_train = len(blurry_imgs_train) // batch_size
    for i in range(num_batches_train):
        start_idx = i * batch_size
        end_idx = start_idx + batch_size

        optimizer.zero_grad()
        outputs_train = model(blurry_imgs_train[start_idx:end_idx])
        loss_train = MSELoss(outputs_train, sharp_imgs_train[start_idx:end_idx]) + L1Loss(outputs_train, sharp_imgs_train[start_idx:end_idx])
        loss_train.backward()
        optimizer.step()
        train_loss += loss_train.item()

    epoch_loss_train = train_loss / num_batches_train

    #validation
    model.eval()
    with torch.no_grad():
        test_loss = 0.0
        num_batches_test = len(blurry_imgs_test) // batch_size
        for i in range(num_batches_test):
            start_idx = i * batch_size
            end_idx = start_idx + batch_size

            outputs_test = model(blurry_imgs_test[start_idx:end_idx])
            loss_test = MSELoss(outputs_test, sharp_imgs_test[start_idx:end_idx]) + L1Loss(outputs_test, sharp_imgs_test[start_idx:end_idx])
            test_loss += loss_test.item()

    epoch_loss_test = test_loss / num_batches_test

    print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss_train:.4f}, Test Loss: {epoch_loss_test:.4f}")
    print(f"----------------------------------")

    return epoch_loss_train, epoch_loss_test

# Train the model
num_epochs = 100 #change the number of epochs
batch_size = 32
best_loss = float('inf')

train_loss_lst, test_loss_lst = [], []
for epoch in range(num_epochs):
    train_loss, test_loss = run_an_epoch(epoch, model, blur_train_.float(), gt_train_.float(), blur_test_.float(), gt_test_.float(),batch_size=batch_size)
    # Store training and testing loss for each epoch
    train_loss_lst.append(train_loss)
    test_loss_lst.append(test_loss)
    # Save the model if it has the best validation loss so far
    if test_loss < best_loss:
        best_loss = test_loss
        torch.save(model.state_dict(), 'autoencoder_best_model.pt')

"""* Plot the training process
* if the best model occurs in the middle of epochs, it is overfitting, otherwise, more traning epochs are needed.
"""

plt.figure(figsize=(8, 8))
x = np.arange(len(train_loss_lst))
plt.title("Optimization curve(Epochs vs MSE loss)")
# y1 = np.log10(torch.Tensor(train_loss_lst).detach().numpy()
y_train = torch.Tensor(train_loss_lst).detach().numpy()
y_test = torch.Tensor(test_loss_lst).detach().numpy()
plt.plot(x, y_train, label="train_loss")
plt.plot(x, y_test, label="val_loss")
plt.plot(np.argmin(y_test), np.min(y_test), marker="x", color="r", label="best model")
plt.xlabel("Epochs")
plt.ylabel("loss")
# plt.ylim(-5, 15)
plt.legend()

"""# Step 5: Load the best model and use it to predict RGB images, compared with actral RGB images (ground truth)"""

model.load_state_dict(torch.load('autoencoder_best_model.pt'))

model.eval()

pred = model(blur_test_.float())

# Create a figure with three subplots in a single row
for i in range(len(pred-1)):
  fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 5))
  i=3
# Plot each image in a separate subplot
  axes[0].imshow(blur_test_[i].cpu().numpy().transpose((1, 2, 0)))
  axes[1].imshow(np.array(pred[i].cpu().detach().numpy().transpose((1, 2, 0)), dtype = np.uint8))
  axes[2].imshow(gt_test_[i].cpu().numpy().transpose((1, 2, 0)))

# Add titles to each subplot
  axes[0].set_title("Blurry")
  axes[1].set_title("Output")
  axes[2].set_title("GT")

# Hide the x and y axis ticks and labels
  for ax in axes:
      ax.set_xticks([])
      ax.set_yticks([])
      ax.set_xticklabels([])
      ax.set_yticklabels([])

# Show the plot
  plt.show()

model.eval()

blur=load_images_from_folder("testing",target_size=(2048,2048))

blury=np.stack(blur)
print(blury.shape)
blury=np.transpose(blury,(0,3,1,2))

blury=torch.from_numpy(blury)

blury=blury.to(device)

pred=model(blury.float())

import matplotlib.pyplot as plt
for i in range(len(pred)):
  fig,axes=plt.subplots(nrows=1,ncols=2,figsize=(10,5))


  axes[0].imshow(blury[i].cpu().numpy().transpose(1,2,0))
  axes[1].imshow(np.array(pred[i].cpu().detach().numpy().transpose((1,2,0)),dtype=np.uint8))

